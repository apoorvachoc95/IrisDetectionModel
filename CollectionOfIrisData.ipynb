{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8d-PTMjUcqz9"
      },
      "outputs": [],
      "source": [
        "# Installing all the dependencies and settig up the environment\n",
        "\n",
        "!pip install labelme albumentations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Collecting all the images for performing Iris detection\n",
        "\n",
        "import os\n",
        "import time\n",
        "import uuid\n",
        "import cv2"
      ],
      "metadata": {
        "id": "esnpDFexc7c-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGES_PATH = '/content/drive/MyDrive/aug_data'\n",
        "number_images = 80"
      ],
      "metadata": {
        "id": "gbXhp8w8c-Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "if cap.isOpened():\n",
        "    current_frame = 0\n",
        "while True:\n",
        "  for imgnum in range(number_images):\n",
        "    print('Collecting image {}'.format(imgnum))\n",
        "    ret, frame = cap.read()\n",
        "    imgname = os.path.join(IMAGES_PATH,f'{str(uuid.uuid1())}.jpg')\n",
        "    cv2.imwrite(imgname, frame)\n",
        "    cv2.imshow('frame', frame)\n",
        "    time.sleep(0.5)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "-vXDRZ0jdCnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The Dataset is being created below\n",
        "\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import json\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cbHO27q9dKxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus: \n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ],
      "metadata": {
        "id": "9ThzGO11dTHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(x): \n",
        "    byte_img = tf.io.read_file(x)\n",
        "    img = tf.io.decode_jpeg(byte_img)\n",
        "    return img"
      ],
      "metadata": {
        "id": "gX2ZYQ7cdRVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we are moving matching Labels After performing Annotations using Labelme\n",
        "\n",
        "for folder in ['train','test','val']:\n",
        "    for file in os.listdir(os.path.join('data', folder, 'images')):\n",
        "        \n",
        "        filename = file.split('.')[0]+'.json'\n",
        "        existing_filepath = os.path.join('data','labels', filename)\n",
        "        if os.path.exists(existing_filepath): \n",
        "            new_filepath = os.path.join('data',folder,'labels',filename)\n",
        "            os.replace(existing_filepath, new_filepath)  \n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    print('Running on Google colab...')\n",
        "    drive.mount('/content/drive') \n",
        "except:\n",
        "    print('Running on local machine...')"
      ],
      "metadata": {
        "id": "jDdbGxdNdZs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We are performing image augmentation\n",
        "\n",
        "import albumentations as alb\n",
        "\n"
      ],
      "metadata": {
        "id": "zjIk3p98dkzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmentor = alb.Compose([alb.RandomCrop(width=450, height=450), \n",
        "                         alb.HorizontalFlip(p=0.5), \n",
        "                         alb.RandomBrightnessContrast(p=0.2),\n",
        "                         alb.RandomGamma(p=0.2), \n",
        "                         alb.RGBShift(p=0.2), \n",
        "                         alb.VerticalFlip(p=0.5)], \n",
        "                        keypoint_params=alb.KeypointParams(format='xy', label_fields=['class_labels']))\n",
        "\n",
        "for partition in ['train', 'test', 'val']: \n",
        "    for image in os.listdir(os.path.join(IMAGES_PATH, partition, 'images')):\n",
        "        img = cv2.imread(os.path.join(IMAGES_PATH, partition, 'images', image))\n",
        "\n",
        "        classes = [0,0]\n",
        "        coords = [0,0,0.00001,0.00001]\n",
        "        labelpath = os.path.join(IMAGES_PATH, partition, 'labels', f'{image.split(\".\")[0]}.json')\n",
        "        print(labelpath)\n",
        "        if os.path.exists(labelpath):\n",
        "            with open(labelpath, 'r') as f:\n",
        "                label = json.load(f)\n",
        "\n",
        "            if label['shapes'][0]['label']=='LeftEye': \n",
        "                classes[0] = 1\n",
        "                coords[0] = np.squeeze(label['shapes'][0]['points'])[0]\n",
        "                coords[1] = np.squeeze(label['shapes'][0]['points'])[1]\n",
        "\n",
        "            if label['shapes'][0]['label']=='RightEye':\n",
        "                classes[1] = 1\n",
        "                coords[2] = np.squeeze(label['shapes'][0]['points'])[0]\n",
        "                coords[3] = np.squeeze(label['shapes'][0]['points'])[1]\n",
        "\n",
        "            if len(label['shapes']) > 1:     \n",
        "                if label['shapes'][1]['label'] =='LeftEye': \n",
        "                    classes[0] = 1 \n",
        "                    coords[0] = np.squeeze(label['shapes'][1]['points'])[0]\n",
        "                    coords[1] = np.squeeze(label['shapes'][1]['points'])[1]\n",
        "\n",
        "                if label['shapes'][1]['label'] =='RightEye': \n",
        "                    classes[1] = 1\n",
        "                    coords[2] = np.squeeze(label['shapes'][1]['points'])[0]\n",
        "                    coords[3] = np.squeeze(label['shapes'][1]['points'])[1]\n",
        "            \n",
        "            np.divide(coords, [640,480,640,480])\n",
        "    \n",
        "        try: \n",
        "            for x in range(120):\n",
        "                keypoints = [(coords[:2]), (coords[2:])]\n",
        "                augmenteddata = augmentor(image=img, keypoints=keypoints, class_labels=['LeftEye','RightEye'])\n",
        "                cv2.imwrite(os.path.join(IMAGES_PATH, partition, 'images', f'{image.split(\".\")[0]}.{x}.jpg'), augmenteddata['image'])\n",
        "\n",
        "                annotation = {}\n",
        "                annotation['image'] = image\n",
        "                annotation['class'] = [0,0]\n",
        "                annotation['keypoints'] = [0,0,0,0]\n",
        "\n",
        "                if os.path.exists(labelpath):\n",
        "                    if len(augmenteddata['keypoints']) > 0: \n",
        "                        for idx, cl in enumerate(augmenteddata['class_labels']):\n",
        "                            if cl == 'LeftEye': \n",
        "                                annotation['class'][0] = 1 \n",
        "                                annotation['keypoints'][0] = augmenteddata['keypoints'][idx][0]\n",
        "                                annotation['keypoints'][1] = augmenteddata['keypoints'][idx][1]\n",
        "                            if cl == 'RightEye': \n",
        "                                annotation['class'][1] = 1 \n",
        "                                annotation['keypoints'][2] = augmenteddata['keypoints'][idx][0]\n",
        "                                annotation['keypoints'][3] = augmenteddata['keypoints'][idx][1]\n",
        "                                \n",
        "                annotation['keypoints'] = list(np.divide(annotation['keypoints'], [450,450,450,450]))\n",
        "\n",
        "\n",
        "                with open(os.path.join(IMAGES_PATH, partition, 'labels', f'{image.split(\".\")[0]}.{x}.json'), 'w') as f:\n",
        "                    json.dump(annotation, f)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(e)"
      ],
      "metadata": {
        "id": "LosxNTb2dqot"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}