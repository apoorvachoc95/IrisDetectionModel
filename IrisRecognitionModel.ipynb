{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXyQ2OgECUqF"
      },
      "outputs": [],
      "source": [
        "# Install all the required Dependencies and Setup\n",
        "\n",
        "!pip install labelme tensorflow tensorflow-gpu opencv-contrib-python matplotlib albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mL_-ZfZBC_qH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import json\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Conv2D, Reshape, Dropout\n",
        "from tensorflow.keras.applications import ResNet152V2\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90uaAjZwDCnC"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    print('Running on Google colab...')\n",
        "    drive.mount('/content/drive') \n",
        "except:\n",
        "    print('Running on local machine...')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqognJsBDFOd"
      },
      "outputs": [],
      "source": [
        "# Load the images and the data\n",
        "\n",
        "trainimages = tf.data.Dataset.list_files('/content/drive/MyDrive/aug_data/train/images/*.jpg',shuffle=False)\n",
        "testimages = tf.data.Dataset.list_files('/content/drive/MyDrive/aug_data/test/images/*.jpg',shuffle=False)\n",
        "valimages = tf.data.Dataset.list_files('/content/drive/MyDrive/aug_data/val/images/*.jpg',shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnuWsuGpDHfc"
      },
      "outputs": [],
      "source": [
        "# Load the images\n",
        "\n",
        "def load_image(x): \n",
        "    byte_img = tf.io.read_file(x) # read the file as bytes\n",
        "    img = tf.io.decode_jpeg(byte_img) # convert to jpeg\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sufCXPbdDRc2"
      },
      "outputs": [],
      "source": [
        "trainimages = trainimages.map(load_image) # map is used to apply the image_load function to every image path obtained from tensor flow\n",
        "trainimages = trainimages.map(lambda x: tf.image.resize(x, (250,250)))\n",
        "trainimages = trainimages.map(lambda x: x/255)\n",
        "\n",
        "testimages = testimages.map(load_image)\n",
        "testimages = testimages.map(lambda x: tf.image.resize(x, (250,250)))\n",
        "testimages = testimages.map(lambda x: x/255)\n",
        "\n",
        "valimages = valimages.map(load_image)\n",
        "valimages = valimages.map(lambda x: tf.image.resize(x, (250,250)))\n",
        "valimages = valimages.map(lambda x: x/255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UW3MGI0fDYxQ"
      },
      "outputs": [],
      "source": [
        "# Preparing the Labels\n",
        "\n",
        "def load_labels(label_path):\n",
        "    with open(label_path.numpy(), 'r', encoding = \"utf-8\") as f:\n",
        "        label = json.load(f)\n",
        "    return [label['keypoints']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTOqCvTwDeiQ"
      },
      "outputs": [],
      "source": [
        "trainlabels = tf.data.Dataset.list_files('/content/drive/MyDrive/aug_data/train/labels/*.json', shuffle=False)\n",
        "trainlabels = trainlabels.map(lambda x: tf.py_function(load_labels, [x], [tf.float16]))\n",
        "\n",
        "testlabels = tf.data.Dataset.list_files('/content/drive/MyDrive/aug_data/test/labels/*.json', shuffle=False)\n",
        "testlabels = testlabels.map(lambda x: tf.py_function(load_labels, [x], [tf.float16]))\n",
        "\n",
        "vallabels = tf.data.Dataset.list_files('/content/drive/MyDrive/aug_data/val/labels/*.json', shuffle=False)\n",
        "vallabels = vallabels.map(lambda x: tf.py_function(load_labels, [x], [tf.float16]))\n",
        "\n",
        "# Combining Labels and Images for Iris Detection\n",
        "\n",
        "train = tf.data.Dataset.zip((trainimages, trainlabels))\n",
        "train = train.batch(16)\n",
        "train = train.prefetch(4)\n",
        "\n",
        "test = tf.data.Dataset.zip((testimages, testlabels))\n",
        "test = test.batch(16)\n",
        "test = test.prefetch(4)\n",
        "\n",
        "val = tf.data.Dataset.zip((valimages, vallabels))\n",
        "val = val.batch(16)\n",
        "val = val.prefetch(4)\n",
        "\n",
        "# Viewing Samples\n",
        "\n",
        "datasamples = train.as_numpy_iterator()\n",
        "\n",
        "res = datasamples.next()\n",
        "\n",
        "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
        "for idx in range(4): \n",
        "    sample_image = res[0][idx]\n",
        "    sample_coords = res[1][0][idx]\n",
        "    \n",
        "    cv2.circle(sample_image, tuple(np.multiply(sample_coords[:2], [250,250]).astype(int)), 2, (255,0,0), -1)\n",
        "    cv2.circle(sample_image, tuple(np.multiply(sample_coords[2:], [250,250]).astype(int)), 2, (0,255,0), -1)\n",
        "    \n",
        "    ax[idx].imshow(sample_image)\n",
        "\n",
        "# Building the model by creating the neural network\n",
        "\n",
        "model = Sequential([\n",
        "    Input(shape=(250,250,3)), \n",
        "    ResNet152V2(include_top=False, input_shape=(250,250,3)),\n",
        "    Conv2D(512, 3, padding='same', activation='relu'),\n",
        "    Conv2D(512, 3, padding='same', activation='relu'),\n",
        "    Conv2D(256, 3, 2, padding='same', activation='relu'),\n",
        "    Conv2D(256, 2, 2, activation='relu'),\n",
        "    Dropout(0.05),\n",
        "    Conv2D(4, 2, 2),\n",
        "    Reshape((4,))\n",
        "])\n",
        "\n",
        "# Setting up Losses and Optimizer\n",
        "\n",
        "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.001, decay=0.0007)\n",
        "loss = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "model.compile(optimizer, loss)\n",
        "\n",
        "# Sense Check predictions\n",
        "\n",
        "X, y = train.as_numpy_iterator().next()\n",
        "\n",
        "scores = model.predict(X)\n",
        "\n",
        "# Training the model for 100 epochs\n",
        "hist = model.fit(train, epochs=10, validation_data=val)\n",
        "\n",
        "# Viewing the Loss Plots\n",
        "\n",
        "plt.plot(hist.history['loss'], color='blue', label='loss')\n",
        "plt.plot(hist.history['val_loss'], color='orange', label='val loss')\n",
        "plt.suptitle('Loss')\n",
        "plt.autoscale() \n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Making the Predictions on Test\n",
        "\n",
        "testdata = test.as_numpy_iterator()\n",
        "\n",
        "testsample = testdata.next()\n",
        "\n",
        "yhat = model.predict(testsample[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQYIX5IVExvM"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
        "for idx in range(4): \n",
        "    sample_image = testsample[0][idx]\n",
        "    sample_coords = yhat[idx]\n",
        "    \n",
        "    cv2.circle(sample_image, tuple(np.multiply(sample_coords[:2], [250,250]).astype(int)), 2, (255,0,0), -1)\n",
        "    cv2.circle(sample_image, tuple(np.multiply(sample_coords[2:], [250,250]).astype(int)), 2, (0,255,0), -1)\n",
        "    \n",
        "    ax[idx].imshow(sample_image)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Viewing the Loss Plots\n",
        "\n",
        "hist.history\n",
        "plt.plot(hist.history['loss'], color='blue', label='loss')\n",
        "plt.plot(hist.history['val_loss'], color='orange', label='val loss')\n",
        "plt.suptitle('Loss')\n",
        "plt.autoscale() \n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lnM_CBHQ8BdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing Real Time Detection\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "while cap.isOpened():\n",
        "    _ , frame = cap.read()\n",
        "    \n",
        "    frame = frame[50:500,50:500,:] \n",
        "    rgb_img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    resized = cv2.resize(rgb_img, (250,250))\n",
        "    \n",
        "    yhat = model.predict(np.expand_dims(resized/255,0))\n",
        "    sample_coords = yhat[0,:4]\n",
        "    \n",
        "    cv2.circle(frame, tuple(np.multiply(sample_coords[:2], [450,450]).astype(int)), 2, (255,0,0), -1)\n",
        "    cv2.circle(frame, tuple(np.multiply(sample_coords[2:], [450,450]).astype(int)), 2, (0,255,0), -1)\n",
        "    \n",
        "    cv2.imshow('EyeTrack', frame)\n",
        "    \n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "SrO4N1XikrxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_oz_H0B8E5AM"
      },
      "outputs": [],
      "source": [
        "# Saving the Model\n",
        "\n",
        "model.save('eyetrackerresnet.h5')\n",
        "model = load_model('eyetrackerresnet.h5')\n",
        "model.predict(testsample[0])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}